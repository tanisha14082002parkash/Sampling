{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKRHXs3/kQplvO4/hQuqns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanisha14082002parkash/Sampling/blob/main/Untitled24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22cbc77QDJXr",
        "outputId": "c91e0f1e-1221-4bb9-915e-2744a5742ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "        Sampling1   Sampling2   Sampling3   Sampling4   Sampling5    \n",
            "M1    0.6000       0.9935       0.9935       0.9935       0.3806   \n",
            "M2    0.5032       0.9548       0.9290       0.9290       0.7484   \n",
            "M3    0.5742       0.9935       0.9935       0.9935       0.7935   \n",
            "M4    0.6839       0.9935       0.9935       0.9935       0.5161   \n",
            "M5    0.6129       0.9935       0.9935       0.9935       0.5548   \n",
            "M6    0.7226       0.9935       0.9935       0.9935       0.4839   \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the z-value and margin of error for each sampling technique\n",
        "z = 2.576  # 99% confidence interval\n",
        "m = 0.05  # margin of error\n",
        "# Calculate the sample size for each sampling technique using the formula\n",
        "n1 = int(np.ceil((z**2 * 0.1 * (1-0.1)) / (m**2)))\n",
        "n2 = int(np.ceil((z**2 * 0.06 * (1-0.06)) / (m**2)))\n",
        "n3 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n4 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n5 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "\n",
        "# Define the sampling techniques and models\n",
        "sampler1 = RandomUnderSampler(sampling_strategy='majority', random_state=0)\n",
        "sampler2 = RandomOverSampler(sampling_strategy='minority', random_state=0)\n",
        "sampler3 = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "sampler4 = TomekLinks(sampling_strategy='majority')\n",
        "sampler5 = NearMiss(version=3, n_neighbors=4)\n",
        "\n",
        "model1 = LogisticRegression(random_state=42,max_iter=500)\n",
        "model2 = DecisionTreeClassifier(random_state=0)\n",
        "model3 = RandomForestClassifier(random_state=0)\n",
        "model4 = SVC(random_state=0)\n",
        "model5 = ExtraTreesClassifier(random_state=0)\n",
        "model6 = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "# Define a dictionary to hold the sampling techniques and models\n",
        "samplers = {\n",
        "    'Sampling1': sampler1,\n",
        "    'Sampling2': sampler2,\n",
        "    'Sampling3': sampler3,\n",
        "    'Sampling4': sampler4,\n",
        "    'Sampling5': sampler5,\n",
        "}\n",
        "models = {\n",
        "    'M1': model1,\n",
        "    'M2': model2,\n",
        "    'M3': model3,\n",
        "    'M4': model4,\n",
        "    'M5': model5,\n",
        "    'M6': model6\n",
        "}\n",
        "\n",
        "# Evaluate each model on each sampling technique\n",
        "results = {}\n",
        "for sampler_name, sampler in samplers.items():\n",
        "    if sampler_name == 'Sampling1':\n",
        "        n = n1\n",
        "    elif sampler_name == 'Sampling2':\n",
        "        n = n2\n",
        "    elif sampler_name == 'Sampling3':\n",
        "        n = n3\n",
        "    elif sampler_name == 'Sampling4':\n",
        "        n = n4\n",
        "    else:\n",
        "        n = n5\n",
        "\n",
        "    # Undersample or oversample the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    \n",
        "    # Limit the resampled data to the sample size\n",
        "    if len(X_resampled) > n:\n",
        "        X_resampled = X_resampled[:n]\n",
        "        y_resampled = y_resampled[:n]\n",
        "    \n",
        "    for model_name, model in models.items():\n",
        "        # Train the model on the resampled data\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate the accuracy score\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        \n",
        "        # Add the accuracy score to the results dictionary\n",
        "        if model_name in results:\n",
        "            results[model_name][sampler_name] = accuracy\n",
        "        else:\n",
        "            results[model_name] = {sampler_name: accuracy}\n",
        "            \n",
        "# Print the results\n",
        "print('Results:')\n",
        "print('        Sampling1   Sampling2   Sampling3   Sampling4   Sampling5    ')\n",
        "for model_name, model_results in results.items():\n",
        "    print(model_name, end='')\n",
        "    for sampler_name in samplers.keys():\n",
        "        if sampler_name in model_results:\n",
        "            print(f'    {model_results[sampler_name]:.4f}   ', end='')\n",
        "        else:\n",
        "            print('              ', end='')\n",
        "    print() "
      ]
    }
  ]
}